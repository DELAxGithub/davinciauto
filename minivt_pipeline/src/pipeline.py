import argparse, json, os, pathlib, re
from dotenv import load_dotenv
from utils.wrap import split_two_lines
from utils.srt import Cue, distribute_by_audio_length, build_srt
from pydub import AudioSegment
from clients.tts_elevenlabs import tts_elevenlabs_per_line, TTSError
from utils.cost_tracker import CostTracker
from config.voice_presets import VoicePresetManager

def _write(path: str, content: str):
    """
    Write content to file, creating parent directories if needed.
    
    Args:
        path: Target file path
        content: Content to write
    """
    pathlib.Path(os.path.dirname(path)).mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f: f.write(content)

def parse_script(script_text: str):
    """
    å°æœ¬ã® 'NA:' / 'ã‚»ãƒªãƒ•:' ã‚’æŠ½å‡ºã—ã€[{role, text}] ã‚’è¿”ã™ï¼ˆç™»å ´é †ï¼‰ã€‚
    """
    items = []
    for line in script_text.splitlines():
        s = line.strip()
        if not s: 
            continue
        if s.startswith("NA:"):
            items.append({"role":"NA", "text": s.replace("NA:", "", 1).strip()})
        elif s.startswith("ã‚»ãƒªãƒ•:"):
            items.append({"role":"DL", "text": s.replace("ã‚»ãƒªãƒ•:", "", 1).strip()})
        # ãã‚Œä»¥å¤–ï¼ˆè¦‹å‡ºã—ãªã©ï¼‰ã¯ç„¡è¦–
    return items

def main(args):
    """
    Main pipeline execution: script â†’ TTS â†’ subtitles â†’ DaVinci output.
    
    Process flow:
    1. Parse script format (NA:/ã‚»ãƒªãƒ•: lines)
    2. Generate TTS audio with voice switching
    3. Create time-synced SRT subtitles
    4. Output structured JSON for validation
    
    Args:
        args: Command line arguments with script path, rate, and flags
    """
    load_dotenv()
    script_text = open(args.script, "r", encoding="utf-8").read()
    items = parse_script(script_text)
    if not items:
        raise RuntimeError("å°æœ¬ã‹ã‚‰ 'NA:' ã¾ãŸã¯ 'ã‚»ãƒªãƒ•:' ã®è¡ŒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    
    # ã‚³ã‚¹ãƒˆè¿½è·¡åˆæœŸåŒ–
    cost_tracker = CostTracker()

    # 1) TTSï¼ˆè¡Œã”ã¨ãƒœã‚¤ã‚¹åˆ‡æ›¿ï¼‰ or ç„¡éŸ³
    try:
        if args.fake_tts:
            est = max(2.5 * len(items), 3.0)
            audio_path = os.path.join("output","audio","narration.mp3")
            pathlib.Path(os.path.dirname(audio_path)).mkdir(parents=True, exist_ok=True)
            AudioSegment.silent(duration=int(est*1000), frame_rate=44100).export(audio_path, format="mp3")
            piece_files = []
        else:
            audio_path, piece_files = tts_elevenlabs_per_line(
                items, 
                out_dir="output/audio", 
                rate=args.rate, 
                cost_tracker=cost_tracker,
                enable_voice_parsing=not args.disable_voice_parsing,
                voice_preset=args.voice_preset
            )
    except TTSError as e:
        print(f"[WARN] TTS failed: {e}\n--> Falling back to silent audio.")
        audio_path = os.path.join("output","audio","narration.mp3")
        AudioSegment.silent(duration=int(max(2.5*len(items),3.0)*1000), frame_rate=44100).export(audio_path, format="mp3")
        piece_files = []

    # 2) å­—å¹•ï¼ˆå„è¡Œãƒ†ã‚­ã‚¹ãƒˆã‚’2è¡ŒåŒ–ï¼‰
    subs = [{"text_2line": split_two_lines(it["text"])} for it in items]

    # 3) ã‚¿ã‚¤ãƒ ã‚³ãƒ¼ãƒ‰ï¼ˆéŸ³å£°å°ºã‹ã‚‰å‡ç­‰å‰²ã‚Šï¼‰â†’SRT
    audio_len = AudioSegment.from_file(audio_path).duration_seconds
    times = distribute_by_audio_length(len(subs), audio_len, 1.8)
    cues=[Cue(idx=i,start=tt[0],end=tt[1],lines=sub["text_2line"]) for i,(sub,tt) in enumerate(zip(subs,times),1)]
    srt=build_srt(cues)
    _write("output/subtitles/script.srt", srt)

    # aeneasç”¨ãƒ—ãƒ¬ãƒ¼ãƒ³
    plain_lines = ["".join(x["text_2line"]) for x in subs]
    _write("output/subtitles_plain.txt", "\n".join(plain_lines))

    # JSONï¼ˆæ¤œè¨¼ç”¨ã«ç°¡æ˜“æ§‹é€ ã‚’ä¿å­˜ï¼‰
    pack = {
        "items": items,
        "audio_path": audio_path,
        "pieces": piece_files,
        "subtitles": subs
    }
    pathlib.Path("output/storyboard").mkdir(parents=True, exist_ok=True)
    with open("output/storyboard/pack.json","w",encoding="utf-8") as f:
        json.dump(pack, f, ensure_ascii=False, indent=2)

    # ã‚³ã‚¹ãƒˆæƒ…å ±è¡¨ç¤ºã¨ä¿å­˜
    if not args.fake_tts:
        print(cost_tracker.get_cost_summary())
        log_file = cost_tracker.save_usage_log()
        print(f"- Usage log: {log_file}")
        
        # ç´¯ç©ä½¿ç”¨é‡è¡¨ç¤º
        total_usage = cost_tracker.get_total_usage()
        if total_usage["total_requests"] > len(cost_tracker.session_requests):
            print(f"ğŸ“Š Total usage: Â¥{total_usage['estimated_total_cost_jpy']} ({total_usage['total_requests']} total requests)")
    
    print("âœ… Completed.")
    print("- Audio:   ", audio_path)
    print("- SRT:     output/subtitles/script.srt")
    print("- Plain:   output/subtitles_plain.txt")
    print("- JSON:    output/storyboard/pack.json")

if __name__=="__main__":
    ap=argparse.ArgumentParser()
    ap.add_argument("--script", help="å…¥åŠ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«")
    ap.add_argument("--rate", type=float, default=1.0, help="å†ç”Ÿé€Ÿåº¦å€ç‡")
    ap.add_argument("--fake-tts", action="store_true", help="TTSã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦ç„¡éŸ³ã‚’ç”Ÿæˆï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰")
    ap.add_argument("--voice-preset", choices=["narration", "dialogue", "emotional", "documentary", "commercial"], 
                    help="éŸ³å£°å“è³ªãƒ—ãƒªã‚»ãƒƒãƒˆ")
    ap.add_argument("--list-presets", action="store_true", help="åˆ©ç”¨å¯èƒ½ãªãƒ—ãƒªã‚»ãƒƒãƒˆä¸€è¦§ã‚’è¡¨ç¤º")
    ap.add_argument("--disable-voice-parsing", action="store_true", help="éŸ³å£°æŒ‡ç¤ºè§£æã‚’ç„¡åŠ¹åŒ–")
    args=ap.parse_args()
    
    # ãƒ—ãƒªã‚»ãƒƒãƒˆä¸€è¦§è¡¨ç¤º
    if args.list_presets:
        preset_manager = VoicePresetManager()
        print("ğŸ¤ åˆ©ç”¨å¯èƒ½ãªéŸ³å£°ãƒ—ãƒªã‚»ãƒƒãƒˆ:")
        for name, info in preset_manager.list_presets().items():
            print(f"  {name}: {info['name']} - {info['description']}")
        exit(0)
    
    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦
    if not args.script:
        ap.error("--script is required unless using --list-presets")
    
    main(args)
