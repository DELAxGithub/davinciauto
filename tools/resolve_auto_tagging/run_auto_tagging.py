#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# --- å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã™ã¹ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ---
import sys
import os
import subprocess
import base64
import hashlib
import yaml
import argparse
from pathlib import Path
from datetime import datetime
from typing import List, Optional
from dotenv import load_dotenv, find_dotenv

# --- DaVinci Resolve APIã®ãƒ‘ã‚¹è¨­å®š ---
sys.path.append("/Library/Application Support/Blackmagic Design/DaVinci Resolve/Developer/Scripting/Modules/")
try:
    import DaVinciResolveScript as dvr_script
except ImportError:
    print("ã‚¨ãƒ©ãƒ¼: DaVinci Resolveã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    sys.exit(1)

# --- .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿ ---
# DaVinci Resolve ã®ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ç­‰ã§ã¯ __file__ ãŒç„¡ã„å ´åˆãŒã‚ã‚‹ãŸã‚è€ƒæ…®
try:
    _BASE_DIR = Path(__file__).resolve().parent
except NameError:
    _BASE_DIR = Path(os.getcwd())

_ENV_PATH = _BASE_DIR / ".env"
if _ENV_PATH.exists():
    load_dotenv(dotenv_path=_ENV_PATH)
else:
    # ã‚«ãƒ¬ãƒ³ãƒˆã‚„ä¸Šä½ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æ¢ç´¢
    _found = find_dotenv()
    load_dotenv(_found if _found else None)

# --- ã“ã‚Œã¾ã§ã®è¨­å®šã¨é–¢æ•°ã‚’ã™ã¹ã¦çµ±åˆ ---

# ã‚°ãƒ­ãƒ¼ãƒãƒ«è¨­å®š
THUMBNAIL_DIR = "thumbnails" # ä¸€æ™‚çš„ãªã‚µãƒ ãƒã‚¤ãƒ«ä¿å­˜å ´æ‰€
VIDEO_EXTENSIONS = ('.mp4', '.mov', '.mxf', '.avi', '.braw')
FFMPEG_PATH = '/opt/homebrew/bin/ffmpeg'
VOCAB_FILE = os.getenv("VOCAB_FILE", "controlled_vocab.yaml")

# --- LLM ãƒ—ãƒ­ãƒã‚¤ãƒ€è¨­å®š ---
DEFAULT_PROVIDER = os.getenv("LLM_PROVIDER", "gemini").lower()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-pro")


class _Tee:
    """stdout/stderr ã‚’æŒ‡å®šãƒ•ã‚¡ã‚¤ãƒ«ã¸è¤‡è£½ã™ã‚‹è–„ã„ Tee."""

    def __init__(self, *streams):
        self._streams = streams

    def write(self, data: str) -> None:
        for stream in self._streams:
            stream.write(data)

    def flush(self) -> None:
        for stream in self._streams:
            stream.flush()

def get_openai_client():
    try:
        from openai import OpenAI  # é…å»¶ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ç’°å¢ƒã‚’è€ƒæ…®ï¼‰
    except ImportError:
        raise RuntimeError("openai ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚--provider gemini ã§å®Ÿè¡Œã™ã‚‹ã‹ã€'pip install openai' ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚")
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    return OpenAI(api_key=api_key, base_url=base_url) if base_url else OpenAI(api_key=api_key)

def get_gemini_model():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        return genai.GenerativeModel(GEMINI_MODEL)
    except ImportError:
        raise RuntimeError("google-generativeai ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install google-generativeai pillow' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

def timecode_to_seconds(timecode_str, fps):
    try:
        clean_tc = timecode_str.replace(';', ':')
        parts = clean_tc.split(':')
        h, m, s, f = [int(p) for p in parts]
        return (h * 3600) + (m * 60) + s + (f / float(fps))
    except Exception:
        return None

def extract_thumbnail(clip_path, output_dir, midpoint_seconds):
    base_filename = os.path.basename(clip_path)
    hash_suffix = hashlib.md5(clip_path.encode("utf-8", "ignore")).hexdigest()[:8]
    stem, _ = os.path.splitext(base_filename)
    safe_stem = stem[:80]
    output_filename = os.path.join(output_dir, f"{safe_stem}_{hash_suffix}.jpg")

    if os.path.exists(output_filename):
        os.remove(output_filename) # å¿µã®ãŸã‚å¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤

    try:
        command = [
            FFMPEG_PATH,
            '-i', clip_path,
            '-ss', str(midpoint_seconds),
            '-vframes', '1',
            '-vf', 'zscale=primariesin=bt709:transferin=bt709:matrixin=bt709:primaries=bt709:transfer=bt709:matrix=bt709,format=yuv420p',
            '-q:v', '3',
            '-f', 'image2',
            '-y', output_filename,
        ]
        subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return output_filename
    except Exception as e:
        print(f"âŒ ã‚µãƒ ãƒã‚¤ãƒ«æŠ½å‡ºã«å¤±æ•—: {e}")
        return None

def load_controlled_vocab(filepath: str) -> Optional[List[str]]:
    try:
        with open(filepath, "r", encoding="utf-8") as f:
            vocab_data = yaml.safe_load(f)
    except FileNotFoundError:
        return None

    if not vocab_data:
        return []

    # schema_version ä»˜ã (Orion ç”¨) ã‚’å„ªå…ˆçš„ã«è§£é‡ˆ
    if isinstance(vocab_data, dict):
        if "vocabulary" in vocab_data:
            vocab_section = vocab_data.get("vocabulary", {}) or {}
            flat: List[str] = []
            for items in vocab_section.values():
                for entry in (items or {}).get("items", []):
                    tag = entry.get("id") or entry.get("label")
                    if tag:
                        flat.append(str(tag))
            return flat

        # æ—§å½¢å¼ {category: [tag, ...]} ã¸ã®å¾Œæ–¹äº’æ›
        flat_list: List[str] = []
        for value in vocab_data.values():
            if isinstance(value, list):
                flat_list.extend(str(item) for item in value)
        return flat_list

    if isinstance(vocab_data, list):
        return [str(item) for item in vocab_data]

    return []

def resolve_path_with_fallbacks(filename: str):
    """'filename' ãŒçµ¶å¯¾ãƒ‘ã‚¹ãªã‚‰ãã®ã¾ã¾ã€‚ç›¸å¯¾ã®å ´åˆã¯è¤‡æ•°ã®å€™è£œã‹ã‚‰æ¢ç´¢ã—ã¦è¿”ã™ã€‚è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° Noneã€‚"""
    # ç’°å¢ƒå¤‰æ•°ã§æ˜ç¤ºæŒ‡å®šãŒã‚ã‚Œã°å„ªå…ˆ
    env_path = os.getenv("VOCAB_PATH")
    if env_path:
        p = Path(os.path.expanduser(env_path))
        if p.exists():
            return str(p)

    # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ’ãƒ³ãƒˆï¼ˆç’°å¢ƒå¤‰æ•°ï¼‰
    for root_env in ("DAVINCIAUTO_ROOT", "PROJECT_ROOT", "REPO_ROOT"):
        root = os.getenv(root_env)
        if root:
            candidate = Path(os.path.expanduser(root)) / filename
            if candidate.exists():
                return str(candidate)

    p = Path(filename)
    if p.is_absolute() and p.exists():
        return str(p)

    # ã¾ãšã¯ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨CWDç›´ä¸‹ã‚’ãƒã‚§ãƒƒã‚¯
    candidates = [
        _BASE_DIR / filename,
        Path.cwd() / filename,
    ]
    for c in candidates:
        if c.exists():
            return str(c)

    # ä¸Šä½ã«æœ€å¤§5éšå±¤ã»ã©é¡ã£ã¦æ¢ç´¢
    for start in {_BASE_DIR, Path.cwd()}:
        cur = start
        for _ in range(5):
            test = cur / filename
            if test.exists():
                return str(test)
            if cur.parent == cur:
                break
            cur = cur.parent

    # ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€å†å¸°æ¤œç´¢ï¼ˆè² è·å›é¿ã®ãŸã‚ã€æ—¢çŸ¥ã®ãƒ«ãƒ¼ãƒˆã®ã¿ï¼‰
    def _looks_like_app_bundle(path: Path) -> bool:
        s = str(path)
        return ".app/Contents" in s or s.endswith(".app")

    def _find_in_subfolders(root: Path, target: str, max_hits: int = 1):
        hits = []
        try:
            for p in root.rglob(target):
                hits.append(p)
                if len(hits) >= max_hits:
                    break
        except Exception:
            return None
        return str(hits[0]) if hits else None

    roots_to_scan = []
    # ãƒ¦ãƒ¼ã‚¶ãŒæ˜ç¤ºã—ãŸãƒ«ãƒ¼ãƒˆ
    for root_env in ("DAVINCIAUTO_ROOT", "PROJECT_ROOT", "REPO_ROOT"):
        rv = os.getenv(root_env)
        if rv:
            pr = Path(os.path.expanduser(rv))
            if pr.exists() and not _looks_like_app_bundle(pr):
                roots_to_scan.append(pr)

    # ã‚¹ã‚¯ãƒªãƒ—ãƒˆåŸºæº–/CWD ã‚‚ .app ç›´ä¸‹ã§ãªã‘ã‚Œã°å€™è£œã«
    if not _looks_like_app_bundle(_BASE_DIR):
        roots_to_scan.append(_BASE_DIR)
    if not _looks_like_app_bundle(Path.cwd()):
        roots_to_scan.append(Path.cwd())

    for root in roots_to_scan:
        found = _find_in_subfolders(root, filename, max_hits=1)
        if found:
            return found
    return None

def encode_image_to_base64(image_path):
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def _mime_type_for(image_path: str) -> str:
    ext = os.path.splitext(image_path.lower())[-1]
    if ext in (".jpg", ".jpeg"):
        return "image/jpeg"
    if ext == ".png":
        return "image/png"
    if ext == ".webp":
        return "image/webp"
    return "image/jpeg"

def _normalize_tags(raw: str) -> List[str]:
    if not raw:
        return []
    raw = raw.replace("ï¼›", ";").replace("ï¼Œ", ",")
    candidates = raw.split(",")
    tags: List[str] = []
    for fragment in candidates:
        for token in fragment.split(";"):
            cleaned = token.strip()
            if cleaned and cleaned not in tags:
                tags.append(cleaned)
    return tags


def analyze_image_with_ai(image_path, vocabulary, provider=DEFAULT_PROVIDER):
    print(f"ğŸ¤– AIãŒç”»åƒã‚’åˆ†æä¸­: {os.path.basename(image_path)} ...")
    vocab_string = ", ".join(vocabulary)
    prompt_text = f"""
    ã‚ãªãŸã¯ãƒ—ãƒ­ã®æ˜ åƒç·¨é›†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ã‚ãªãŸã®ä»•äº‹ã¯ã€ã“ã®æ˜ åƒç´ æãŒå¾Œã‹ã‚‰ã€Œéƒ½å¸‚ã®å¤œæ™¯ã€ã€Œå­¤ç‹¬æ„Ÿã®ã‚ã‚‹ã‚·ãƒ§ãƒƒãƒˆã€ã¨ã„ã£ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡å˜ã«æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«ã€çš„ç¢ºãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¿ã‚°ï¼‰ã‚’ä»˜ã‘ã‚‹ã“ã¨ã§ã™ã€‚

    # æŒ‡ç¤º
    1. ã¾ãšã€ã“ã®ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã‚‹ã‹ã€ã©ã‚“ãªé›°å›²æ°—ã‹ã‚’ç°¡æ½”ã«å¿ƒã®ä¸­ã§åˆ†æã—ã¦ãã ã•ã„ã€‚
    2. ãã®åˆ†æã«åŸºã¥ãã€ä»¥ä¸‹ã®ã€Œç®¡ç†èªå½™ãƒªã‚¹ãƒˆã€ã‹ã‚‰æœ€ã‚‚ãµã•ã‚ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æœ€å¤§8å€‹ã¾ã§é¸ã‚“ã§ãã ã•ã„ã€‚
    3. å‡ºåŠ›ã¯ã€é¸ã‚“ã ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã«ã—ãŸæ–‡å­—åˆ—ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚

    # ãƒ«ãƒ¼ãƒ«
    - ã€Œç®¡ç†èªå½™ãƒªã‚¹ãƒˆã€ã«å­˜åœ¨ã™ã‚‹å˜èªã ã‘ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    - è¢«å†™ä½“ã€å ´æ‰€ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒ ãƒ¼ãƒ‰ãªã©ã€å¤šè§’çš„ãªè¦–ç‚¹ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ã€‚
    - ã‚‚ã—ç”»åƒã«äººç‰©ãŒå†™ã£ã¦ã„ãªã‘ã‚Œã°ã€çµ¶å¯¾ã«'people'ã‚„'man'ã®ã‚ˆã†ãªäººç‰©ã‚¿ã‚°ã‚’é¸ã°ãªã„ã§ãã ã•ã„ã€‚

    # ç®¡ç†èªå½™ãƒªã‚¹ãƒˆ
    {vocab_string}
    """
    try:
        if provider == "openai":
            base64_image = encode_image_to_base64(image_path)
            mime = _mime_type_for(image_path)
            client = get_openai_client()
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "text", "text": prompt_text},
                        {"type": "image_url", "image_url": {"url": f"data:{mime};base64,{base64_image}"}},
                    ],
                }],
                max_tokens=100,
            )
            return response.choices[0].message.content
        elif provider == "gemini":
            try:
                import google.generativeai as genai
            except ImportError:
                raise RuntimeError("google-generativeai ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install google-generativeai' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            model = get_gemini_model()
            file = genai.upload_file(path=image_path)
            result = model.generate_content([prompt_text, file])
            return getattr(result, "text", None) or getattr(result, "candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text")
        else:
            raise RuntimeError(f"æœªå¯¾å¿œã®ãƒ—ãƒ­ãƒã‚¤ãƒ€æŒ‡å®šã§ã™: {provider}")
    except Exception as e:
        msg = str(e)
        print(f"âŒ AIã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {msg}")
        if "insufficient_quota" in msg or "You exceeded your current quota" in msg:
            print("ãƒ’ãƒ³ãƒˆ: OpenAIã®ã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ã§ã™ã€‚--provider gemini ã§å®Ÿè¡Œã€ã¾ãŸã¯ .env ã® LLM_PROVIDER=gemini ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        return None

# --- Media Pool ã‚’å†å¸°çš„ã«æ¢ç´¢ã—ã¦å…¨ã‚¯ãƒªãƒƒãƒ—ã‚’å–å¾— ---
def get_media_pool_clips(folder):
    clip_list = []
    clips = folder.GetClipList()
    if clips:
        clip_list.extend(clips)
    for sub_folder in folder.GetSubFolderList():
        clip_list.extend(get_media_pool_clips(sub_folder))
    return clip_list

# --- ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œéƒ¨åˆ† ---
def main() -> int:
    parser = argparse.ArgumentParser(description="DaVinci Resolve clips auto-tagging using OpenAI/Gemini.")
    parser.add_argument("-p", "--provider", choices=["openai", "gemini"], default=DEFAULT_PROVIDER, help="ä½¿ç”¨ã™ã‚‹LLMãƒ—ãƒ­ãƒã‚¤ãƒ€")
    parser.add_argument("--model", default=None, help="ãƒ¢ãƒ‡ãƒ«åã‚’ä¸Šæ›¸ãï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ã«å¿œã˜ã¦ï¼‰")
    parser.add_argument("-v", "--vocab", default=None, help="ç®¡ç†èªå½™YAMLã®ãƒ‘ã‚¹ï¼ˆæœªæŒ‡å®šæ™‚ã¯è‡ªå‹•æ¢ç´¢ï¼‰")
    parser.add_argument("--env", dest="env_file", default=None, help="èª­ã¿è¾¼ã‚€ .env ã®ãƒ‘ã‚¹ï¼ˆResolveç’°å¢ƒãªã©ã§æ¨å¥¨ï¼‰")
    parser.add_argument("--project", dest="project_name", default=None, help="å¯¾è±¡ã®Resolveãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå")
    parser.add_argument("--limit", type=int, default=None, help="å‡¦ç†ã™ã‚‹ã‚¯ãƒªãƒƒãƒ—æ•°ã®ä¸Šé™")
    parser.add_argument("--skip", type=int, default=0, help="æœ€åˆã®Nä»¶ã®å¯¾è±¡ã‚¯ãƒªãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    parser.add_argument("--only-untagged", action="store_true", help="æ—¢ã«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒã‚ã‚‹ã‚¯ãƒªãƒƒãƒ—ã‚’ã‚¹ã‚­ãƒƒãƒ—")
    parser.add_argument("--batch", type=int, default=0, help="é€²æ—ã‚’è¡¨ç¤ºã™ã‚‹å‡¦ç†ä»¶æ•°é–“éš” (0 ã§ç„¡åŠ¹)")
    parser.add_argument("--merge-policy", choices=["append_unique", "replace"], default="append_unique", help="æ—¢å­˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨ã®çªãåˆã‚ã›æ–¹")
    parser.add_argument("--dry-run", action="store_true", help="æ›¸ãè¾¼ã¿ã‚’è¡Œã‚ãšäºˆå®šã®å¤‰æ›´å†…å®¹ã®ã¿è¡¨ç¤º")
    parser.add_argument("--thumbnails", dest="thumbnail_dir", default=None, help="ã‚µãƒ ãƒã‚¤ãƒ«å‡ºåŠ›å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª")
    parser.add_argument("--log", dest="log_path", default=None, help="ãƒ­ã‚°ã‚’è¿½è¨˜å‡ºåŠ›ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    args = parser.parse_args()

    original_stdout, original_stderr = sys.stdout, sys.stderr
    log_file = None
    try:
        if args.log_path:
            log_path = os.path.expanduser(args.log_path)
            log_dir = os.path.dirname(log_path) or "."
            os.makedirs(log_dir, exist_ok=True)
            log_file = open(log_path, "a", encoding="utf-8")
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            header = f"\n--- run_auto_tagging.py started at {timestamp} ---\n"
            log_file.write(header)
            log_file.flush()
            tee_stdout = _Tee(original_stdout, log_file)
            tee_stderr = _Tee(original_stderr, log_file)
            sys.stdout = tee_stdout
            sys.stderr = tee_stderr

        # æŒ‡å®šãŒã‚ã‚Œã° .env ã‚’è¿½åŠ èª­ã¿è¾¼ã¿ï¼ˆç’°å¢ƒå¤‰æ•°ã‚’ä¸Šæ›¸ãï¼‰
        if args.env_file:
            env_path = os.path.expanduser(args.env_file)
            if os.path.exists(env_path):
                load_dotenv(dotenv_path=env_path, override=True)
            else:
                print(f"è­¦å‘Š: æŒ‡å®šã® .env ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {env_path}")

        # ãƒ¢ãƒ‡ãƒ«åã®ä¸Šæ›¸ã
        global OPENAI_MODEL, GEMINI_MODEL
        if args.model:
            if args.provider == "openai":
                OPENAI_MODEL = args.model
            else:
                GEMINI_MODEL = args.model
        # Resolveã«æ¥ç¶š
        try:
            resolve = dvr_script.scriptapp("Resolve")
            project_manager = resolve.GetProjectManager()
            project = None
            if args.project_name:
                project = project_manager.LoadProject(args.project_name)
                if project is None:
                    print(f"ã‚¨ãƒ©ãƒ¼: æŒ‡å®šã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.project_name}")
                    return 1
            else:
                project = project_manager.GetCurrentProject()
                if project is None:
                    print("ã‚¨ãƒ©ãƒ¼: ç¾åœ¨ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã€‚")
                    return 1

            media_pool = project.GetMediaPool()
            root_folder = media_pool.GetRootFolder()
        except Exception as exc:
            print(f"ã‚¨ãƒ©ãƒ¼: DaVinci Resolveã«æ¥ç¶šã§ãã¾ã›ã‚“ã§ã—ãŸã€‚({exc})")
            return 1

        if args.project_name:
            print(f"å¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {args.project_name}")
        else:
            print(f"å¯¾è±¡ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ: {project.GetName() if project else 'æœªå–å¾—'}")

        # ç®¡ç†èªå½™ã‚’èª­ã¿è¾¼ã‚€
        vocab_path = args.vocab or resolve_path_with_fallbacks(VOCAB_FILE)
        if not vocab_path:
            print(
                "ã‚¨ãƒ©ãƒ¼: ç®¡ç†èªå½™ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:\n"
                f" - {_BASE_DIR / VOCAB_FILE}\n"
                f" - {Path.cwd() / VOCAB_FILE}\n"
                "å¯¾å‡¦:\n"
                " - --vocab ã§çµ¶å¯¾ãƒ‘ã‚¹ã‚’æŒ‡å®š\n"
                " - --env ã§ .env ã‚’èª­ã¿è¾¼ã¿ã€.env ã« VOCAB_PATH ã‚’è¨­å®š\n"
                " - ç’°å¢ƒå¤‰æ•° DAVINCIAUTO_ROOTï¼ˆã¾ãŸã¯ PROJECT_ROOT/REPO_ROOTï¼‰ã‚’ãƒªãƒã‚¸ãƒˆãƒªãƒ«ãƒ¼ãƒˆã«è¨­å®š"
            )
            return 1
        vocab = load_controlled_vocab(vocab_path)
        if not vocab:
            print(f"ã‚¨ãƒ©ãƒ¼: ç®¡ç†èªå½™ãƒ•ã‚¡ã‚¤ãƒ« '{vocab_path}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
            return 1

        # ä¸€æ™‚ã‚µãƒ ãƒã‚¤ãƒ«ç”¨ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆ
        # ã‚µãƒ ãƒã‚¤ãƒ«å‡ºåŠ›å…ˆã¯æŒ‡å®šãŒã‚ã‚Œã°å„ªå…ˆ
        script_dir = os.path.dirname(os.path.realpath(__file__)) if '__file__' in locals() else os.getcwd()
        if args.thumbnail_dir:
            thumbnail_output_dir = os.path.expanduser(args.thumbnail_dir)
        else:
            thumbnail_output_dir = os.path.join(script_dir, THUMBNAIL_DIR)
        os.makedirs(thumbnail_output_dir, exist_ok=True)

        # Media Poolã®ã‚¯ãƒªãƒƒãƒ—ã‚’èµ°æŸ»ï¼ˆã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã¾ã§å†å¸°çš„ã«æ¢ç´¢ï¼‰
        print("--- Media Poolã®å…¨ã‚¯ãƒªãƒƒãƒ—ã‚’æ¤œç´¢ä¸­... ---")
        all_clips = get_media_pool_clips(root_folder)

        print("--- è‡ªå‹•ã‚¿ã‚°ä»˜ã‘å‡¦ç†ã‚’é–‹å§‹ ---")
        stats = {
            "processed": 0,
            "eligible": 0,
            "tagged": 0,
            "appended": 0,
            "replaced": 0,
            "skipped_no_duration": 0,
            "skipped_ai_empty": 0,
            "skipped_no_change": 0,
            "errors": 0,
        }

        limit = args.limit if args.limit and args.limit > 0 else None

        skip = max(0, args.skip)
        for clip in all_clips:
            file_path = clip.GetClipProperty("File Path")

            if file_path and file_path.lower().endswith(VIDEO_EXTENSIONS):
                if skip > 0:
                    skip -= 1
                    continue
                if args.only_untagged:
                    existing = clip.GetMetadata("Keywords") or clip.GetClipProperty("Keywords")
                    if existing:
                        continue
                if limit is not None and stats["processed"] >= limit:
                    break

                stats["processed"] += 1
                clip_name = clip.GetName()
                print(f"\nâ–¶ï¸  å‡¦ç†å¯¾è±¡ã‚¯ãƒªãƒƒãƒ—: {clip_name}")

                # 1. ã‚µãƒ ãƒã‚¤ãƒ«æŠ½å‡º
                duration_tc = clip.GetClipProperty("Duration")
                fps = clip.GetClipProperty("FPS")
                duration_sec = timecode_to_seconds(duration_tc, fps)

                if not duration_sec or duration_sec <= 0:
                    print("âš ï¸ æ™‚é–“ãŒå–å¾—ã§ããšã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    stats["skipped_no_duration"] += 1
                    continue

                stats["eligible"] += 1
                thumb_path = extract_thumbnail(file_path, thumbnail_output_dir, duration_sec / 2.0)
                if not thumb_path:
                    stats["errors"] += 1
                    continue

                # 2. AIã§åˆ†æ
                ai_tags_str = analyze_image_with_ai(thumb_path, vocab, provider=args.provider)
                os.remove(thumb_path) # ã‚µãƒ ãƒã‚¤ãƒ«ã¯ã™ãã«å‰Šé™¤

                if not ai_tags_str:
                    print("âš ï¸ AIã‹ã‚‰ã‚¿ã‚°ãŒè¿”ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸã€‚")
                    stats["skipped_ai_empty"] += 1
                    continue

                # 3. Resolveã«æ›¸ãæˆ»ã—
                normalized_tags = _normalize_tags(ai_tags_str)
                if not normalized_tags:
                    print("âš ï¸ æ­£å¸¸åŒ–å¾Œã«ã‚¿ã‚°ãŒæ®‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
                    stats["skipped_ai_empty"] += 1
                    continue

                existing_keywords_raw = (
                    clip.GetMetadata("Keywords")
                    or clip.GetClipProperty("Keywords")
                    or ""
                )
                if isinstance(existing_keywords_raw, (list, tuple)):
                    existing_keywords_raw = ";".join(existing_keywords_raw)
                existing_keywords = _normalize_tags(str(existing_keywords_raw))

                if args.merge_policy == "append_unique":
                    merged_keywords = existing_keywords[:]
                    newly_added = []
                    for tag in normalized_tags:
                        if tag not in merged_keywords:
                            merged_keywords.append(tag)
                            newly_added.append(tag)
                    keywords_changed = bool(newly_added)
                    if keywords_changed:
                        stats["appended"] += 1
                else:  # replace
                    merged_keywords = normalized_tags
                    keywords_changed = merged_keywords != existing_keywords
                    if keywords_changed:
                        stats["replaced"] += 1

                if not keywords_changed:
                    print("â„¹ï¸ æ—¢å­˜ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¨å¤‰åŒ–ãªã—ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    stats["skipped_no_change"] += 1
                    continue

                tags_for_resolve = "; ".join(merged_keywords)

                if args.dry_run:
                    print(f"[DRY-RUN] {clip_name}: {tags_for_resolve}")
                    stats["tagged"] += 1
                else:
                    success = clip.SetMetadata("Keywords", tags_for_resolve)
                    if success:
                        print(f"âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æ›¸ãè¾¼ã¿ã¾ã—ãŸ: [{tags_for_resolve}]")
                        stats["tagged"] += 1
                    else:
                        print("âŒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
                        stats["errors"] += 1

                if args.batch and args.batch > 0 and stats["processed"] % args.batch == 0:
                    print(
                        f"... é€²æ—: å‡¦ç†={stats['processed']} / æˆåŠŸ={stats['tagged']} / "
                        f"è¿½åŠ ={stats['appended']} / ç½®æ›={stats['replaced']} ..."
                    )

        print("\n--- å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ ---")
        print(
            "ã‚µãƒãƒª: "
            f"å‡¦ç†={stats['processed']} / å¯¾è±¡={stats['eligible']} / æˆåŠŸ={stats['tagged']} / "
            f"è¿½åŠ ={stats['appended']} / ç½®æ›={stats['replaced']} / "
            f"æ™‚é–“å–å¾—å¤±æ•—={stats['skipped_no_duration']} / AIç„¡å¿œç­”={stats['skipped_ai_empty']} / å¤‰åŒ–ãªã—={stats['skipped_no_change']} / ã‚¨ãƒ©ãƒ¼={stats['errors']}"
        )

        if log_file:
            log_file.write("--- run_auto_tagging.py finished ---\n")

        return 0 if stats["errors"] == 0 else 1
    finally:
        if log_file:
            log_file.flush()
            log_file.close()
        sys.stdout = original_stdout
        sys.stderr = original_stderr

if __name__ == "__main__":
    sys.exit(main())
