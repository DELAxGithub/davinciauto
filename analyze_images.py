#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import base64
from pathlib import Path
import yaml  # PyYAMLãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import argparse
from openai import OpenAI
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€ï¼ˆã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ã‚ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’åŸºæº–ã«æ¢ç´¢ï¼‰
ENV_PATH = (Path(__file__).resolve().parent / ".env")
if ENV_PATH.exists():
    load_dotenv(dotenv_path=ENV_PATH)
else:
    # CWDã‹ã‚‰ã®æ¢ç´¢ã«ã‚‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    load_dotenv()

# --- è¨­å®šé …ç›® ---
THUMBNAIL_DIR = "thumbnails"
VOCAB_FILE = "controlled_vocab.yaml"

# ãƒ—ãƒ­ãƒã‚¤ãƒ€è¨­å®šï¼ˆenv/CLIã§åˆ‡æ›¿ï¼‰
DEFAULT_PROVIDER = os.getenv("LLM_PROVIDER", "openai").lower()
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-pro")

def get_openai_client():
    """OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ã—ã¦è¿”ã™ï¼ˆå¿…è¦ãªã¨ãã®ã¿ï¼‰ã€‚"""
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = os.getenv("OPENAI_BASE_URL")  # ä»»æ„ï¼ˆOpenAIäº’æ›ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆç”¨ï¼‰
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã« 'OPENAI_API_KEY=sk-...' ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    try:
        return OpenAI(api_key=api_key, base_url=base_url) if base_url else OpenAI(api_key=api_key)
    except Exception as e:
        raise RuntimeError(f"OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–ã«å¤±æ•—: {e}")

def get_gemini_model():
    """Geminiãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–ã—ã¦è¿”ã™ï¼ˆå¿…è¦ãªã¨ãã®ã¿ï¼‰ã€‚"""
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError("GEMINI_API_KEY ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚.env ã« 'GEMINI_API_KEY=...' ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
    try:
        import google.generativeai as genai
        genai.configure(api_key=api_key)
        return genai.GenerativeModel(GEMINI_MODEL)
    except ImportError:
        raise RuntimeError("google-generativeai ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install google-generativeai pillow' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
    except Exception as e:
        raise RuntimeError(f"Geminiãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã«å¤±æ•—: {e}")

def load_controlled_vocab(filepath):
    """YAMLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç®¡ç†èªå½™ã‚’èª­ã¿è¾¼ã‚€"""
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            # YAMLã‚’èª­ã¿è¾¼ã‚“ã§ãƒ•ãƒ©ãƒƒãƒˆãªãƒªã‚¹ãƒˆã«å¤‰æ›
            vocab_data = yaml.safe_load(f)
            flat_vocab_list = []
            for category in vocab_data.values():
                flat_vocab_list.extend(category)
            return flat_vocab_list
    except FileNotFoundError:
        print(f"ã‚¨ãƒ©ãƒ¼: ç®¡ç†èªå½™ãƒ•ã‚¡ã‚¤ãƒ« '{filepath}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return None

def encode_image_to_base64(image_path):
    """ç”»åƒã‚’Base64å½¢å¼ã®æ–‡å­—åˆ—ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã™ã‚‹"""
    with open(image_path, "rb") as image_file:
        return base64.b64encode(image_file.read()).decode('utf-8')

def _mime_type_for(image_path: str) -> str:
    ext = os.path.splitext(image_path.lower())[-1]
    if ext in (".jpg", ".jpeg"):
        return "image/jpeg"
    if ext == ".png":
        return "image/png"
    if ext == ".webp":
        return "image/webp"
    return "image/jpeg"

def analyze_image_with_ai(image_path, vocabulary, provider=DEFAULT_PROVIDER):
    """ç”»åƒã¨ç®¡ç†èªå½™ã‚’AIã«é€ã‚Šã€ã‚¿ã‚°ã‚’ç”Ÿæˆã•ã›ã‚‹"""
    print(f"ğŸ¤–  AIãŒç”»åƒã‚’åˆ†æä¸­: {os.path.basename(image_path)} ...")

    # ç®¡ç†èªå½™ãƒªã‚¹ãƒˆã‚’æ–‡å­—åˆ—ã«å¤‰æ›
    vocab_string = ", ".join(vocabulary)

    # æ–°ã—ã„ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆç·¨é›†è€…å‘ã‘ã®æ˜ç¢ºãªå½¹å‰²ãƒ»ç›®çš„ä»˜ä¸ï¼‰
    prompt_text = f"""
    ã‚ãªãŸã¯ãƒ—ãƒ­ã®æ˜ åƒç·¨é›†ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
    ã‚ãªãŸã®ä»•äº‹ã¯ã€ã“ã®æ˜ åƒç´ æãŒå¾Œã‹ã‚‰ã€Œéƒ½å¸‚ã®å¤œæ™¯ã€ã€Œå­¤ç‹¬æ„Ÿã®ã‚ã‚‹ã‚·ãƒ§ãƒƒãƒˆã€ã¨ã„ã£ãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ç°¡å˜ã«æ¤œç´¢ã§ãã‚‹ã‚ˆã†ã«ã€çš„ç¢ºãªãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆã‚¿ã‚°ï¼‰ã‚’ä»˜ã‘ã‚‹ã“ã¨ã§ã™ã€‚

    # æŒ‡ç¤º
    1. ã¾ãšã€ã“ã®ç”»åƒã«ä½•ãŒå†™ã£ã¦ã„ã‚‹ã‹ã€ã©ã‚“ãªé›°å›²æ°—ã‹ã‚’ç°¡æ½”ã«å¿ƒã®ä¸­ã§åˆ†æã—ã¦ãã ã•ã„ã€‚
    2. ãã®åˆ†æã«åŸºã¥ãã€ä»¥ä¸‹ã®ã€Œç®¡ç†èªå½™ãƒªã‚¹ãƒˆã€ã‹ã‚‰æœ€ã‚‚ãµã•ã‚ã—ã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æœ€å¤§8å€‹ã¾ã§é¸ã‚“ã§ãã ã•ã„ã€‚
    3. å‡ºåŠ›ã¯ã€é¸ã‚“ã ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã«ã—ãŸæ–‡å­—åˆ—ã®ã¿ã«ã—ã¦ãã ã•ã„ã€‚

    # ãƒ«ãƒ¼ãƒ«
    - ã€Œç®¡ç†èªå½™ãƒªã‚¹ãƒˆã€ã«å­˜åœ¨ã™ã‚‹å˜èªã ã‘ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
    - è¢«å†™ä½“ã€å ´æ‰€ã€ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã€ãƒ ãƒ¼ãƒ‰ãªã©ã€å¤šè§’çš„ãªè¦–ç‚¹ã‹ã‚‰é¸ã‚“ã§ãã ã•ã„ã€‚
    - ã‚‚ã—ç”»åƒã«äººç‰©ãŒå†™ã£ã¦ã„ãªã‘ã‚Œã°ã€çµ¶å¯¾ã«'people'ã‚„'man'ã®ã‚ˆã†ãªäººç‰©ã‚¿ã‚°ã‚’é¸ã°ãªã„ã§ãã ã•ã„ã€‚

    # ç®¡ç†èªå½™ãƒªã‚¹ãƒˆ
    {vocab_string}
    """

    try:
        if provider == "openai":
            # OpenAI Vision
            base64_image = encode_image_to_base64(image_path)
            client = get_openai_client()
            mime = _mime_type_for(image_path)
            response = client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt_text},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:{mime};base64,{base64_image}"},
                            },
                        ],
                    }
                ],
                max_tokens=100,
            )
            return response.choices[0].message.content

        elif provider == "gemini":
            # Google Gemini Visionï¼ˆãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§Pillowä¾å­˜ã‚’æ’é™¤ï¼‰
            try:
                import google.generativeai as genai
            except ImportError:
                raise RuntimeError("google-generativeai ãŒæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ã™ã€‚'pip install google-generativeai' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            model = get_gemini_model()
            file = genai.upload_file(path=image_path)
            result = model.generate_content([prompt_text, file])
            return getattr(result, "text", None) or getattr(result, "candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text")

        else:
            raise RuntimeError(f"æœªå¯¾å¿œã®ãƒ—ãƒ­ãƒã‚¤ãƒ€æŒ‡å®šã§ã™: {provider}")

    except Exception as e:
        msg = str(e)
        print(f"âŒ  AIã®åˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {msg}")
        if "insufficient_quota" in msg or "You exceeded your current quota" in msg:
            print("ãƒ’ãƒ³ãƒˆ: OpenAIã®ã‚¯ã‚©ãƒ¼ã‚¿ä¸è¶³ã§ã™ã€‚--provider gemini ã§å®Ÿè¡Œã€ã¾ãŸã¯ .env ã® LLM_PROVIDER=gemini ã‚’è¨­å®šã—ã¦å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
        return None


def main():
    parser = argparse.ArgumentParser(description="Analyze thumbnail images and suggest tags from a controlled vocabulary.")
    parser.add_argument(
        "-t", "--thumbnails",
        help="ã‚µãƒ ãƒã‚¤ãƒ«ç”»åƒãƒ•ã‚©ãƒ«ãƒ€ã¸ã®ãƒ‘ã‚¹ï¼ˆä¾‹: /Users/you/Desktop/resolve_thumbnails/thumbnailsï¼‰",
        default=None,
    )
    parser.add_argument(
        "-v", "--vocab",
        help="ç®¡ç†èªå½™YAMLãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ‘ã‚¹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: controlled_vocab.yamlï¼‰",
        default=VOCAB_FILE,
    )
    parser.add_argument(
        "-p", "--provider",
        help="ä½¿ç”¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ï¼ˆopenai / geminiï¼‰",
        choices=["openai", "gemini"],
        default=DEFAULT_PROVIDER,
    )
    parser.add_argument(
        "--model",
        help="ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«åï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ã«å¿œã˜ã¦è§£é‡ˆ: OpenAIãªã‚‰ OPENAI_MODELã€Geminiãªã‚‰ GEMINI_MODEL ã‚’ä¸Šæ›¸ãï¼‰",
        default=None,
    )
    args = parser.parse_args()

    # ç®¡ç†èªå½™ã‚’èª­ã¿è¾¼ã‚€
    vocab = load_controlled_vocab(args.vocab)
    if not vocab:
        return

    # ã‚µãƒ ãƒã‚¤ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ã®ãƒ‘ã‚¹ã‚’æ±ºå®š
    project_dir = os.getcwd()
    if args.thumbnails:
        thumbnail_path = os.path.expanduser(args.thumbnails)
    else:
        # ã‚«ãƒ¬ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç›´ä¸‹ã‚’å„ªå…ˆã—ã€ãªã‘ã‚Œã° output/thumbnails ã‚‚æ¢ç´¢
        thumbnail_path = os.path.join(project_dir, THUMBNAIL_DIR)
        if not os.path.isdir(thumbnail_path):
            alt_path = os.path.join(project_dir, "output", THUMBNAIL_DIR)
            if os.path.isdir(alt_path):
                thumbnail_path = alt_path

    if not os.path.isdir(thumbnail_path):
        print(
            "ã‚¨ãƒ©ãƒ¼: ã‚µãƒ ãƒã‚¤ãƒ«ãƒ•ã‚©ãƒ«ãƒ€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã‚’ä½œæˆ/æŒ‡å®šã—ã¦ãã ã•ã„:\n"
            f" - {os.path.join(project_dir, THUMBNAIL_DIR)}\n"
            f" - {os.path.join(project_dir, 'output', THUMBNAIL_DIR)}\n"
            "ã¾ãŸã¯ --thumbnails ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã§çµ¶å¯¾ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
        )
        return

    # ãƒ¢ãƒ‡ãƒ«ä¸Šæ›¸ã
    global OPENAI_MODEL, GEMINI_MODEL
    if args.model:
        if args.provider == "openai":
            OPENAI_MODEL = args.model
        elif args.provider == "gemini":
            GEMINI_MODEL = args.model

    print(f"ã‚µãƒ ãƒã‚¤ãƒ«ãƒ•ã‚©ãƒ«ãƒ€: {thumbnail_path}")
    print(f"ãƒ—ãƒ­ãƒã‚¤ãƒ€: {args.provider} / ãƒ¢ãƒ‡ãƒ«: {OPENAI_MODEL if args.provider=='openai' else GEMINI_MODEL}")

    # ãƒ•ã‚©ãƒ«ãƒ€å†…ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ï¼ˆä¸»è¦æ‹¡å¼µå­ã‚’ã‚µãƒãƒ¼ãƒˆï¼‰
    exts = (".jpg", ".jpeg", ".png", ".webp")
    thumbnail_files = [f for f in os.listdir(thumbnail_path) if f.lower().endswith(exts)]

    if not thumbnail_files:
        print("åˆ†æå¯¾è±¡ã®ã‚µãƒ ãƒã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return

    # --- ãƒ†ã‚¹ãƒˆã®ãŸã‚ã€æœ€åˆã®1æšã ã‘ã‚’åˆ†æ ---
    first_image_path = os.path.join(thumbnail_path, thumbnail_files[0])

    generated_tags = analyze_image_with_ai(first_image_path, vocab, provider=args.provider)

    if generated_tags:
        print("\n--- AIã«ã‚ˆã‚‹åˆ†æçµæœ ---")
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«: {thumbnail_files[0]}")
        print(f"ææ¡ˆã•ã‚ŒãŸã‚¿ã‚°: {generated_tags}")
        print("--------------------")

if __name__ == "__main__":
    main()
